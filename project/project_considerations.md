## üéØ **PREMISSAS FUNDAMENTAIS**

### **1. Qualidade dos Dados (CR√çTICO)**

**Premissas que precisamos validar:**
- ‚úÖ Dados representam comportamento real (n√£o apenas subset enviesado)
- ‚úÖ Per√≠odo de an√°lise √© suficiente para padr√µes sazonais (m√≠n. 12 meses)
- ‚úÖ Transa√ß√µes canceladas est√£o marcadas corretamente
- ‚úÖ CustomerID est√° presente na maioria das transa√ß√µes (>70%)

**Red flags comuns neste dataset UCI:**
- ~25% das transa√ß√µes SEM CustomerID ‚Üí decis√£o: excluir ou imputar?
- Quantidades negativas = devolu√ß√µes/cancelamentos
- Pre√ßos unit√°rios ‚â§ 0 ou extremamente altos (outliers ou erros?)
- Invoices duplicadas ou parcialmente canceladas

**A√ß√£o Senior:**
```python
# SEMPRE documentar decis√µes de limpeza
data_quality_report = {
    "missing_customer_id": "24.93% - DECIS√ÉO: Excluir (imposs√≠vel segmentar)",
    "negative_quantities": "8,905 linhas - DECIS√ÉO: Marcar como returns",
    "outlier_prices": "327 produtos >¬£1000 - DECIS√ÉO: Manter (luxo v√°lido)"
}
# Justificar para stakeholders!
```

---

### **2. Defini√ß√£o de M√©tricas Alinhadas ao Neg√≥cio**

**CUIDADO:** M√©tricas t√©cnicas ‚â† m√©tricas de neg√≥cio

**Erros comuns:**
- ‚ùå "Consegui Silhouette Score de 0.65!" ‚Üí **E da√≠? Como isso impacta revenue?**
- ‚ùå "Modelo de churn com 92% accuracy" ‚Üí **Mas qual o custo de falso negativo?**

**Abordagem Senior:**
```python
# Definir m√©tricas de NEG√ìCIO primeiro
business_metrics = {
    "Segmentation Success": "Vari√¢ncia inter-cluster de CLV > 40%",
    "Actionability": "Cada segmento tem ‚â•500 clientes (vi√°vel para campanha)",
    "Churn Model ROI": "Saving > 3x campaign cost (n√£o s√≥ accuracy)",
    "Recommendation CTR": "Lift >15% vs. baseline random recommendations"
}
```

**Framework de valida√ß√£o:**
- Modelo t√©cnico pode ser perfeito, mas se n√£o gerar a√ß√£o ‚Üí falhou

---

### **3. Contexto de Neg√≥cio do Varejo UK**

**Premissas importantes:**
- Dataset √© de **varejo B2B** (atacado de presentes/decora√ß√£o)
- Muitos clientes s√£o **revendedores**, n√£o consumidores finais
- Comportamento B2B ‚â† B2C (compras em lote, sazonalidade diferente)

**Impacto nas decis√µes:**
- RFM tradicional pode n√£o funcionar bem (compras bulk s√£o normais)
- "Churn" pode ser sazonal (loja fecha no inverno)
- Recomenda√ß√µes devem considerar mix de produtos para revenda

**A√ß√£o Senior:**
```python
# Adaptar RFM para contexto B2B
rfm_thresholds = {
    "recency": [30, 60, 120, 240],  # B2B tem ciclos mais longos
    "frequency": [2, 5, 10, 20],     # Menos frequente que B2C
    "monetary": [500, 2000, 5000, 15000]  # Tickets muito maiores
}
```

---

## ‚ö†Ô∏è **PONTOS CR√çTICOS DE ATEN√á√ÉO**

### **1. Data Leakage (MORTAL para credibilidade)**

**Cen√°rios perigosos:**

**Leakage temporal:**
```python
# ‚ùå ERRADO - usando dados do futuro
X = df[['recency', 'frequency', 'monetary', 'total_revenue']]
# total_revenue inclui compras futuras!

# ‚úÖ CORRETO - split temporal rigoroso
train_cutoff = '2011-09-01'
test_cutoff = '2011-12-01'

train = df[df['InvoiceDate'] < train_cutoff]
test = df[(df['InvoiceDate'] >= train_cutoff) & 
          (df['InvoiceDate'] < test_cutoff)]
```

**Leakage de features:**
```python
# ‚ùå ERRADO - "churn" √© o que queremos prever
features = ['days_since_last', 'avg_basket', 'is_churned']

# ‚úÖ CORRETO - apenas info dispon√≠vel ANTES do evento
features = ['days_since_last', 'avg_basket', 'trend_last_3months']
```

---

### **2. Overfitting em Segmenta√ß√£o**

**Problema:** Criar 47 micro-segmentos que n√£o s√£o acion√°veis

**Princ√≠pio Senior:**
```python
# Regra de ouro
min_segment_size = max(
    500,  # M√≠nimo absoluto para campanha
    len(customers) * 0.05  # Pelo menos 5% da base
)

# Valida√ß√£o de acionabilidade
for segment in segments:
    if segment['size'] < min_segment_size:
        print(f"‚ö†Ô∏è Segmento '{segment['name']}' muito pequeno - FUNDIR")
    
    if segment['revenue_variance'] < 0.15:
        print(f"‚ö†Ô∏è Segmento '{segment['name']}' sem diferencia√ß√£o - REVISAR")
```

**Teste pr√°tico:**
> "Se eu apresentar isso para o CMO, ele consegue criar 1 campanha espec√≠fica para este segmento?"

Se a resposta for n√£o ‚Üí segmento in√∫til

---

### **3. Interpretabilidade vs. Performance**

**Dilema comum:**
```python
# Modelo complexo: XGBoost com 150 features
# - Accuracy: 94%
# - Explicabilidade: ‚ùå "√© tipo magia negra"

# vs.

# Modelo simples: Logistic Regression com 8 features
# - Accuracy: 87%
# - Explicabilidade: ‚úÖ "cada aumento de 1 em X aumenta churn em Y%"
```

**Decis√£o Senior:**
- Para **segmenta√ß√£o**: SEMPRE priorize interpretabilidade (K-Means > DBSCAN)
- Para **scoring**: Balance performance com explica√ß√µes (SHAP values ajudam)
- Para **produ√ß√£o**: Simplicidade > complexidade (manuten√ß√£o futura)

**Regra de ouro:**
> "Se n√£o consigo explicar em 2 minutos para o time de marketing, modelo n√£o vai ser usado"

---

### **4. Vi√©s de Sobreviv√™ncia (Survivorship Bias)**

**Problema:** Dataset s√≥ tem clientes que COMPRARAM

**O que est√° faltando:**
- Clientes que abandonaram carrinho
- Visitantes que nunca compraram
- Clientes que churned ANTES do per√≠odo de an√°lise

**Impacto:**
```python
# ‚ùå Conclus√£o enviesada
"Nosso churn rate √© apenas 15%!"
# Mas 15% de QUEM? S√≥ de quem j√° comprou pelo menos 2x...

# ‚úÖ Conclus√£o correta
"Entre clientes ativos em Jan/2010, 15% n√£o compraram mais at√© Dez/2011"
# Deixar claro o denominador
```

**A√ß√£o Senior:**
- Documentar limita√ß√µes explicitamente
- Criar "cohorts" claros (ex: "clientes adquiridos em Q1 2011")
- Nunca generalizar al√©m do escopo dos dados

---

### **5. Correla√ß√£o ‚â† Causalidade (CR√çTICO para recomenda√ß√µes)**

**Exemplo perigoso:**
```python
# An√°lise mostra:
"Clientes que compram produto A t√™m 3x mais lifetime value"

# ‚ùå Recomenda√ß√£o ing√™nua
"Vamos empurrar produto A para todos!"

# Problema: 
# Produto A √© caro ‚Üí s√≥ clientes ricos compram ‚Üí CLV alto √© CAUSA, n√£o efeito
```

**Framework Senior:**
1. **Identificar confounders** (vari√°veis de confus√£o)
2. **Testar hip√≥teses reversas** ("e se a rela√ß√£o for inversa?")
3. **Usar linguagem cautelosa** ("associado com" vs. "causa")
4. **Propor testes A/B** para validar causalidade

---

### **6. Escala e Performance em Produ√ß√£o**

**Cuidados com c√≥digo "notebook-friendly" que quebra em produ√ß√£o:**

```python
# ‚ùå C√≥digo de notebook (funciona com 500k linhas)
df['new_feature'] = df.apply(lambda x: complex_function(x), axis=1)
# Tempo: 45 minutos

# ‚úÖ C√≥digo production-ready
df['new_feature'] = df.groupby('customer_id')['value'].transform('sum')
# Tempo: 3 segundos
```

**Checklist de produ√ß√£o:**
- [ ] C√≥digo vetorizado (evitar loops quando poss√≠vel)
- [ ] Mem√≥ria gerenciada (usar chunks para dados grandes)
- [ ] Features replic√°veis (sem random seeds n√£o controlados)
- [ ] Pipeline serializado (salvar preprocessors com modelo)

---

## üìã **CHECKLIST DE DECIS√ïES CR√çTICAS**

### **Antes de come√ßar:**
- [ ] Defini per√≠odo de an√°lise e justificativa?
- [ ] Mapeei todas as fontes de dados faltantes?
- [ ] Alinhe defini√ß√£o de "cliente ativo" com stakeholders?
- [ ] Estabeleci baseline para comparar modelos?

### **Durante an√°lise:**
- [ ] Documentei TODAS decis√µes de limpeza de dados?
- [ ] Validei premissas estat√≠sticas (normalidade, etc.)?
- [ ] Testei robustez das conclus√µes (sensitivity analysis)?
- [ ] Criei visualiza√ß√µes que executivos entendam?

### **Antes de entregar:**
- [ ] Resultados fazem sentido de NEG√ìCIO (n√£o s√≥ estat√≠stico)?
- [ ] Consegui explicar em linguagem n√£o-t√©cnica?
- [ ] Identifiquei limita√ß√µes e pr√≥ximos passos?
- [ ] C√≥digo est√° reproduz√≠vel (requirements.txt, seeds, etc.)?

---

## üéì **PRINC√çPIOS DE UM SENIOR DATA SCIENTIST**

### **1. Ceticismo Saud√°vel**
```python
# Sempre pergunte:
"Este resultado √© BOM DEMAIS para ser verdade?"
"Estou vendo padr√£o real ou ru√≠do?"
"E se eu estiver errado? Qual o impacto?"
```

### **2. Transpar√™ncia Radical**
```python
# Documente incertezas
model_report = {
    "confidence": "M√©dia-Alta",
    "limitations": [
        "Dataset n√£o inclui clientes B2C",
        "Per√≠odo de an√°lise limitado (12 meses)",
        "Sem dados de marketing campaigns"
    ],
    "assumptions": [
        "Comportamento futuro similar ao passado",
        "CustomerID mapping est√° correto"
    ]
}
```

### **3. Business Outcome First**
```python
# Sempre alinhe com m√©trica de neg√≥cio
if technical_metric_improved and not business_metric_improved:
    print("‚ö†Ô∏è MODELO IN√öTIL - revisar abordagem")
```

### **4. C√≥digo como Comunica√ß√£o**
```python
# ‚ùå C√≥digo de junior
df2 = df1[df1['col3'] > df1['col2'].quantile(0.9)]

# ‚úÖ C√≥digo de senior
high_value_customers = customers[
    customers['lifetime_value'] > customers['lifetime_value'].quantile(0.9)
]
# Nomes descritivos > coment√°rios
```

---

## üö® **RED FLAGS para Abortar/Pivotar**

**Pare e reavalie se:**
1. **>40% dos dados precisam ser descartados** ‚Üí dataset pode ser inadequado
2. **Segmentos t√™m overlap >60%** ‚Üí clustering n√£o est√° encontrando padr√µes reais
3. **Modelo performa igual ao baseline** ‚Üí features n√£o t√™m poder preditivo
4. **Stakeholders n√£o entendem resultados** ‚Üí comunica√ß√£o falhou
5. **Recomenda√ß√µes n√£o s√£o acion√°veis** ‚Üí an√°lise √© academicamente interessante, mas in√∫til

---

## ‚úÖ **RESUMO EXECUTIVO: O que fazer AGORA**

### **Antes de codar 1 linha:**

1. **Baixar e fazer scan inicial do dataset**
   - Row count, column types, missing %
   - Identificar surpresas cedo

2. **Definir 3-5 perguntas de neg√≥cio espec√≠ficas**
   - "Quais segmentos t√™m maior potencial de crescimento?"
   - "Qual timing ideal para reengajar clientes inativos?"
   - "Quais produtos devemos bundling juntos?"

3. **Criar documento de decis√µes**
   - Markdown file: `DECISIONS.md`
   - Registrar cada escolha metodol√≥gica e POR QU√ä

4. **Setup de ambiente reproduz√≠vel**
   ```bash
   # requirements.txt com vers√µes fixas
   pandas==2.0.3
   scikit-learn==1.3.0
   # etc
   ```

---
